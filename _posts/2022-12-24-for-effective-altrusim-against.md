---
title: For effective altruism, but against Effective Altruism
layout: post
---

There is nothing wrong, and much right, about promoting altruism. You are privileged and have more than you need; others need your surplus (be it resources or time); sharing it is good and laudable. Encouraging others to do the same is good and laudable too.

There is also nothing wrong, and much right, about striving for altruism to be effective. You could share your surplus to charitable efforts that achieve nothing, or to others that are almost certain to alleviate extreme suffering—indeed, to save lives. Personal sympathies for specific causes aside (and personal sympathies are quite important!), advocating for effective charities as the default target for our efforts is worthwhile.

Being an altruist, an *effective* altruist, seems commonsensically good. I wish altruism was well established in our society, and I wish altruists gravitated towards charities with proven benefits for those in dire need.

And so you may be forgiven if you find a community called “Effective Altruism” (EA) and assumed this is what it’s doing. It says it does, and it looks like it does at first, if you squint, and I suspect many in the community have been squinting for a long time. But its leaders have a tendency to follow philosophical rabbit holes that land them in positions that would seem satirical, were they not taken in earnest.

The core of the problem, I think, is that Effective Altruist leaders are not trying to be effective altruists, but maximizing altruists. They want to find the way in which they can do *the most good*, and they have the hubris to imagine they can do it. This maximization impulse is a black hole. It pulls every effort into the initiative with the greatest Expected Value.

This is how you get to [longtermism](https://www.currentaffairs.org/2021/07/the-dangerous-ideas-of-longtermism-and-existential-risk), the current (but not first) cancer of EA. There are 8 billion of us today. There may be 8 trillion some day; there may be none if we go extinct. If we think that life is worth living, then 8 trillion is way better than 8 billion, and bringing about that future, eliminating the obstacles in its path, becomes the one thing that matters. This goal overrides everything: by this logic, poverty, famine, climate change, war, and genocide, while deplorable, are mere ripples in comparison to the catastrophe of extinction, or to the tragedy of failing to fulfill our galactic potential.

The conclusion of this stance is abhorrent, and longtermists, knowing it is unsellable, attempt to paper over its monstrousness with platitudes. They know it is a gruesome position. I sometimes suspect that, deep down, they are themselves not convinced of its validity. But they lock themselves within it via rhetorical tricks.

The main longtermist trick is disguised with mathematics—it consists of adding zeroes to the side of the equation you favour until you get the answer you want. For instance, via creative hand-waving, we can say that in the far future the Milky Way could support a ridiculously high number of human lives, say 10^58. If there’s no actual physical space for such a large number, we can always say some of those will live in simulation form. If you have a remotely minute chance of helping, via your actions, to bring about that future, or help those incomprehensible large numbers of humans be even remotely happy, then the maximization calculation overwhelms every other alternative to ease suffering in the world. And if you run the numbers and the longtermist solution does not come out on top? Just add another zero or two or ten to your expected number of humans in the far future and you’ll be all set. You can use any number you want from the vast unknowable future to justify your prefered alternative in the present.

The consequence is the exact opposite of being effective with our altruism: it entails the dismissal of attempts to ease actual suffering today, especially in the Global South. Longtermist leaders have advocated for focusing only on existential risks, for valuing lives in the developed world higher than those elsewhere (because of their greater potential to advance cutting-edge science), and for funding Artificial Intelligence research initiatives—led, it has to be said, by their friends and contacts—rather than bringing people out of poverty. They advocate for giving money to their peers and acolytes, because those are the people that *really get it*.

Today, Effective Altruism is licking its wounds from its association with the Sam Bankman-Fried implosion. Perhaps the movement will not recover, and perhaps that’s a good thing. And yet, I wish people separated actual effective altruism from the EA label. Lately, I’ve seen a lot of derision thrown at people trying to be effective with their altruism, and I think that’s unfortunate.

Do you donate your time or money to improve the lot in life of others? You are an altruist. (And if you don’t—*why not?* If you are reading this, you are probably luckier than most, living in relative luxury, and as Singer’s [Drowning Child](https://daily-philosophy.com/peter-singers-drowning-child/) thought experiment illustrates, you are at least partially responsible to mitigate their suffering. Your generosity can quite literally save lives.)

Do you donate to causes that are likely to actually make a difference? You are trying to be an effective altruist. Please, keep sending your funds to global charities that have extensively demonstrated to have a good impact—[GiveWell](https://www.givewell.org/charities/top-charities) keeps the best list—, or to local charities you trust, and keep giving your time as best you can.

And do you think we’d be in a better spot if more of us did the same? Well, then you have the seeds of an effective altruism movement... but beware: movements evolve in the most unfortunate ways.
